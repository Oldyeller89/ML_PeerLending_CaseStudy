{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 - Ingestion and Cleaning\n",
    "\n",
    "In the Phase 2 of the Case Study, we will carry out the following steps:\n",
    "  - Ingest raw downloaded data\n",
    "  - Output a combined dataset ready for analysis and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sys import platform\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function that you'll be using while reading the raw files\n",
    "def is_integer(x):\n",
    "    '''\n",
    "    This function returns True if x is an integer, and False otherwise\n",
    "    '''\n",
    "    try:\n",
    "        return (int(x) == float(x))\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directories that contain the files downloaded\n",
    "dir_cs = \"/case_study_data.zip\" # path to the directory where all the *.csv.zip files are located\n",
    "\n",
    "# Define the output path for the pickle\n",
    "pickle_file = \"loanData/\" + \"clean_data.pickle\" # path to save cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the columns we'll be keeping from the dataset\n",
    "cols_to_pick = [\"id\", \"loan_amnt\", \"funded_amnt\", \"term\", \"int_rate\", \"installment\", \"grade\", \"emp_length\", \\\n",
    "                \"home_ownership\", \"annual_inc\", \"verification_status\", \"issue_d\", \"loan_status\", \"purpose\", \\\n",
    "                \"dti\", \"delinq_2yrs\", \"earliest_cr_line\", \"open_acc\", \"pub_rec\",\"fico_range_high\", \"fico_range_low\", \\\n",
    "                \"revol_bal\", \"revol_util\", \"total_pymnt\", \"last_pymnt_d\", \"recoveries\"] # list of features to use for this study as indicated in the handout\n",
    "\n",
    "# Identify the type of each of these column based on your CS-Phase 1 response\n",
    "float_cols = [\"loan_amnt\", \"funded_amnt\", \"installment\", \"annual_inc\", \"dti\", \"delinq_2yrs\", \"open_acc\", \"pub_rec\", \\\n",
    "              \"fico_range_high\", \"fico_range_low\", \"revol_bal\", \"total_pymnt\", \"recoveries\"]\n",
    "cat_cols = [\"term\", \"grade\", \"emp_length\", \"home_ownership\", \"verification_status\", \"loan_status\", \"purpose\"] # categorical features\n",
    "perc_cols = ['int_rate', 'revol_util']\n",
    "date_cols = ['issue_d', 'earliest_cr_line', 'last_pymnt_d']\n",
    "\n",
    "# Ensure that we have types for every column\n",
    "assert set(cols_to_pick) - set(float_cols) - set(cat_cols) - set(perc_cols) - set(date_cols) == set([\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the columns selected will not be used directly in the model,\n",
    "# but will be used to generate other features.\n",
    "#\n",
    "# Create variables specifying the features that will be used\n",
    "\n",
    "# All categorical columns other than \"loan_status\" will be used as\n",
    "# discrete features\n",
    "\n",
    "discrete_features = list(set(cat_cols) - set([\"loan_status\"]))\n",
    "\n",
    "# All numeric columns will be used as continuous features\n",
    "continuous_features = list(float_cols + perc_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestion\n",
    "Ingest the data files from both sets, perform consistency checks, and prepare one single file for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def ingest_files(directory):\n",
    "    '''\n",
    "    This function will ingest every file in the specified directory\n",
    "    into a pandas dataframe. It will return a dictionary containing\n",
    "    these dataframes, keyed by the file name.\n",
    "    \n",
    "    We assume the directory contains files directly downloaded from\n",
    "    the link given in the handout, and *only* those files. Thus, we \n",
    "    assume the files are zipped (pd.read_csv can read zipped files) \n",
    "    and we assume the first line in each file needs to be skipped.\n",
    "    \n",
    "    Note that each file will be read *without* formatting\n",
    "    '''\n",
    "    \n",
    "    # If the directory has no trailing slash, add one\n",
    "    if directory[-1] != \"/\":\n",
    "        directory += \"/\"\n",
    "    \n",
    "    all_files = glob.glob(directory+\"*.zip\") # get list of all files from the directory\n",
    "    output = {}\n",
    "    \n",
    "    print(\"Directory \" + directory + \" has \" + str(len(all_files)) + \" files:\")\n",
    "    for i in all_files:\n",
    "        print(\"    Reading file \" + i)\n",
    "        output[i] = pd.read_csv(i, dtype='str', skiprows=1) # read each with dtype='str' and skip_rows =1\n",
    "        \n",
    "        # Some of the files have \"summary\" lines that, for example\n",
    "        # read \"Total number of loans number in Policy 1: .....\"\n",
    "        # To remove those lines, find any lines with non-integer IDs\n",
    "        # and remove them\n",
    "        invalid_rows = [not is_integer(r) for r in output[i]['id']] # mask rows that have non-integer IDs. Use is_integer method\n",
    "       \n",
    "        if sum(invalid_rows) > 0:\n",
    "            print(\"Found \" + str(sum(invalid_rows)) + \" invalid rows which were removed\")\n",
    "            output[i] = output[i][np.logical_not(invalid_rows)] # remove invalid rows\n",
    "    \n",
    "    return output # return dictionary of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory case_study_data/1805_download/ has 12 files:\n",
      "    Reading file case_study_data/1805_download\\LoanStats3a_securev1.csv.zip\n",
      "Found 3 invalid rows which were removed\n",
      "    Reading file case_study_data/1805_download\\LoanStats3b_securev1.csv.zip\n",
      "Found 2 invalid rows which were removed\n",
      "    Reading file case_study_data/1805_download\\LoanStats3c_securev1.csv.zip\n",
      "Found 2 invalid rows which were removed\n",
      "    Reading file case_study_data/1805_download\\LoanStats3d_securev1.csv.zip\n",
      "Found 2 invalid rows which were removed\n",
      "    Reading file case_study_data/1805_download\\LoanStats_securev1_2016Q1.csv.zip\n",
      "Found 2 invalid rows which were removed\n",
      "    Reading file case_study_data/1805_download\\LoanStats_securev1_2016Q2.csv.zip\n",
      "Found 2 invalid rows which were removed\n",
      "    Reading file case_study_data/1805_download\\LoanStats_securev1_2016Q3.csv.zip\n",
      "Found 2 invalid rows which were removed\n",
      "    Reading file case_study_data/1805_download\\LoanStats_securev1_2016Q4.csv.zip\n",
      "Found 2 invalid rows which were removed\n",
      "    Reading file case_study_data/1805_download\\LoanStats_securev1_2017Q1.csv.zip\n",
      "Found 2 invalid rows which were removed\n",
      "    Reading file case_study_data/1805_download\\LoanStats_securev1_2017Q2.csv.zip\n",
      "Found 2 invalid rows which were removed\n",
      "    Reading file case_study_data/1805_download\\LoanStats_securev1_2017Q3.csv.zip\n",
      "Found 2 invalid rows which were removed\n",
      "    Reading file case_study_data/1805_download\\LoanStats_securev1_2017Q4.csv.zip\n",
      "Found 2 invalid rows which were removed\n"
     ]
    }
   ],
   "source": [
    "# Ingest the set of files we downloaded using the defined method \"ingest_files\"\n",
    "files_cs = ingest_files(\"case_study_data/1805_download\") # dictionary of (filename, dataframe) as (key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>hardship_payoff_balance_amount</th>\n",
       "      <th>hardship_last_payment_amount</th>\n",
       "      <th>disbursement_method</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "      <th>debt_settlement_flag_date</th>\n",
       "      <th>settlement_status</th>\n",
       "      <th>settlement_date</th>\n",
       "      <th>settlement_amount</th>\n",
       "      <th>settlement_percentage</th>\n",
       "      <th>settlement_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>4975</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27%</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>2400</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96%</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>10000</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49%</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69%</td>\n",
       "      <td>67.79</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id member_id loan_amnt funded_amnt funded_amnt_inv        term  \\\n",
       "0  1077501       NaN      5000        5000            4975   36 months   \n",
       "1  1077430       NaN      2500        2500            2500   60 months   \n",
       "2  1077175       NaN      2400        2400            2400   36 months   \n",
       "3  1076863       NaN     10000       10000           10000   36 months   \n",
       "4  1075358       NaN      3000        3000            3000   60 months   \n",
       "\n",
       "  int_rate installment grade sub_grade       ...        \\\n",
       "0   10.65%      162.87     B        B2       ...         \n",
       "1   15.27%       59.83     C        C4       ...         \n",
       "2   15.96%       84.33     C        C5       ...         \n",
       "3   13.49%      339.31     C        C1       ...         \n",
       "4   12.69%       67.79     B        B5       ...         \n",
       "\n",
       "  hardship_payoff_balance_amount hardship_last_payment_amount  \\\n",
       "0                            NaN                          NaN   \n",
       "1                            NaN                          NaN   \n",
       "2                            NaN                          NaN   \n",
       "3                            NaN                          NaN   \n",
       "4                            NaN                          NaN   \n",
       "\n",
       "  disbursement_method debt_settlement_flag debt_settlement_flag_date  \\\n",
       "0                Cash                    N                       NaN   \n",
       "1                Cash                    N                       NaN   \n",
       "2                Cash                    N                       NaN   \n",
       "3                Cash                    N                       NaN   \n",
       "4                Cash                    N                       NaN   \n",
       "\n",
       "  settlement_status settlement_date settlement_amount settlement_percentage  \\\n",
       "0               NaN             NaN               NaN                   NaN   \n",
       "1               NaN             NaN               NaN                   NaN   \n",
       "2               NaN             NaN               NaN                   NaN   \n",
       "3               NaN             NaN               NaN                   NaN   \n",
       "4               NaN             NaN               NaN                   NaN   \n",
       "\n",
       "  settlement_term  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "\n",
       "[5 rows x 151 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cs = pd.concat(files_cs.values()) # combine \"files_cs\" into a pandas dataframe\n",
    "data_cs.reset_index(drop=True)          # reset index with drop = True\n",
    "data_cs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1765426, 26)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the columns of interest from 'data_cs'\n",
    "final_data = data_cs[cols_to_pick]\n",
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with 1765426 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting with \" + str(len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typecast the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                      object\n",
       "loan_amnt              float64\n",
       "funded_amnt            float64\n",
       "term                    object\n",
       "int_rate                object\n",
       "installment            float64\n",
       "grade                   object\n",
       "emp_length              object\n",
       "home_ownership          object\n",
       "annual_inc             float64\n",
       "verification_status     object\n",
       "issue_d                 object\n",
       "loan_status             object\n",
       "purpose                 object\n",
       "dti                    float64\n",
       "delinq_2yrs            float64\n",
       "earliest_cr_line        object\n",
       "open_acc               float64\n",
       "pub_rec                float64\n",
       "fico_range_high        float64\n",
       "fico_range_low         float64\n",
       "revol_bal              float64\n",
       "revol_util              object\n",
       "total_pymnt            float64\n",
       "last_pymnt_d            object\n",
       "recoveries             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remember that we read the data as string (without any formatting). \n",
    "# Now we would typecast the columns based on feature types which you found out in CS Phase 1\n",
    "\n",
    "for i in float_cols:\n",
    "    final_data[i] = final_data[i].astype(float) # typecast float columns\n",
    "    \n",
    "final_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                      object\n",
       "loan_amnt              float64\n",
       "funded_amnt            float64\n",
       "term                    object\n",
       "int_rate               float64\n",
       "installment            float64\n",
       "grade                   object\n",
       "emp_length              object\n",
       "home_ownership          object\n",
       "annual_inc             float64\n",
       "verification_status     object\n",
       "issue_d                 object\n",
       "loan_status             object\n",
       "purpose                 object\n",
       "dti                    float64\n",
       "delinq_2yrs            float64\n",
       "earliest_cr_line        object\n",
       "open_acc               float64\n",
       "pub_rec                float64\n",
       "fico_range_high        float64\n",
       "fico_range_low         float64\n",
       "revol_bal              float64\n",
       "revol_util             float64\n",
       "total_pymnt            float64\n",
       "last_pymnt_d            object\n",
       "recoveries             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_perc(x):\n",
    "    if type(x) is float:\n",
    "        return x\n",
    "    if pd.isnull(x):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return float(x.strip()[:-1])\n",
    "\n",
    "for i in perc_cols:\n",
    "    final_data[i] = [clean_perc(j) for j in final_data[i]] # apply clean_perc to percentage columns\n",
    "    \n",
    "final_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "def clean_date(x):\n",
    "    if type(x) is datetime.datetime:\n",
    "        return x\n",
    "    if pd.isnull(x):\n",
    "        return None\n",
    "    else:\n",
    "        return datetime.datetime.strptime( x, \"%b-%Y\").date()\n",
    "\n",
    "for i in date_cols:\n",
    "    final_data[i] = [clean_date(d) for d in final_data[i]] # typecast date cloumns to datatime using clean_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_cols:\n",
    "    final_data[i].replace(r'\\s+', None, regex=True, inplace = True) # for categorical features if the value is null/empty set it to None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate returns for each loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the names of the four returns we'll be calculating as described in Q.6\n",
    "# ret_PESS: Pessimistic return\n",
    "# ret_OPT: Optimistic return\n",
    "# ret_INTa, ret_INTb: Method3 at two differnt values of \"i\"\n",
    "ret_cols = [\"ret_PESS\", \"ret_OPT\", \"ret_INTa\", \"ret_INTb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 8006 rows\n"
     ]
    }
   ],
   "source": [
    "# Remove all rows for loans that were paid back on the days they were issued\n",
    "final_data['loan_length'] = (final_data.last_pymnt_d - final_data.issue_d) / np.timedelta64(1, 'M')\n",
    "n_rows = len(final_data)\n",
    "\n",
    "final_data = final_data.loc[final_data['loan_length'] > 0] # select rows where loan_length is not 0. \n",
    "\n",
    "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M1-Pessimistic Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the return using a simple annualized profit margin\n",
    "# Pessimistic definition (Handout 6a.) (M1)\n",
    "\n",
    "final_data['term_num'] = final_data.term.str.extract('(\\d+)',expand=False).astype(int) # length of loan in months\n",
    "\n",
    "final_data['ret_PESS'] = ((final_data['total_pymnt']-final_data['loan_amnt'])/final_data['loan_amnt'] ) * (12/final_data['term_num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M2-Optimistic Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that if a loan gives a positive return, we can\n",
    "# immediately find a similar loan to invest in; if the loan\n",
    "# takes a loss, we use M1-pessimistic to compute the return\n",
    "\n",
    "final_data['ret_OPT'] = ((final_data['total_pymnt']-final_data['loan_amnt'])/final_data['loan_amnt'] ) * (12/final_data['loan_length'])\n",
    "\n",
    "final_data.loc[final_data.ret_OPT < 0,'ret_OPT'] = final_data.loc[final_data.ret_OPT < 0,'ret_PESS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ret_method_3(T, i):\n",
    "    '''\n",
    "    Given an investment time horizon (in months) and re-investment\n",
    "    interest rate, calculate the return of each loan\n",
    "    '''\n",
    "    \n",
    "    # Assuming that the total amount paid back was paid at equal\n",
    "    # intervals during the duration of the loan, calculate the\n",
    "    # size of each of these installment\n",
    "    actual_installment = (final_data.total_pymnt - final_data.recoveries) / ...\n",
    "\n",
    "    # Assuming the amount is immediately re-invested at the prime\n",
    "    # rate, find the total amount of money we'll have by the end\n",
    "    # of the loan\n",
    "    cash_by_end_of_loan = actual_installment * ... # compute the quantity given in [] in eq.2.3 of handout\n",
    "    \n",
    "    cash_by_end_of_loan = cash_by_end_of_loan + final_data.recoveries\n",
    "    \n",
    "    # Assuming that cash is then re-invested at the prime rate,\n",
    "    # with monthly re-investment, until T months from the start\n",
    "    # of the loan\n",
    "    remaining_months = T - final_data['loan_length']\n",
    "    final_return = cash_by_end_of_loan * ... \n",
    "\n",
    "    # Find the percentage return\n",
    "    ret_val = (12/T) * ...\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_data['ret_INTa'] = ... # call ret_method_3 with T=60, i=0.001\n",
    "final_data['ret_INTb'] = ... # call ret_method_3 with T=60, i=0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_float_columns():\n",
    "    '''\n",
    "    This function visualizes Box-and-whisker plots for continuous variables\n",
    "    '''\n",
    "    \n",
    "    # FLoat columns\n",
    "    for i in float_cols + perc_cols + ret_cols:\n",
    "        seaborn.boxplot(final_data[i])\n",
    "\n",
    "        # Print the three highest values\n",
    "        highest_vals = ... # get 3 highest values\n",
    "        \n",
    "        smallest_val = min(final_data[i])\n",
    "        \n",
    "        plt.text(smallest_val, -0.3, highest_vals[0])\n",
    "        plt.text(smallest_val, -0.2, highest_vals[1])\n",
    "        plt.text(smallest_val, -0.1, highest_vals[2])\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_cat_columns():\n",
    "    '''\n",
    "    Lists the distinct values for categorical columns\n",
    "    '''\n",
    "    # Categorical columns \n",
    "    for i in cat_cols:\n",
    "        ... # print field name\n",
    "        ... # print number of distinct values\n",
    "        ... # for each distinct value print the number of occurances\n",
    "        print(\"\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_date_columns():\n",
    "    '''\n",
    "    This function visualizes a timeline density for dates\n",
    "    '''\n",
    "    \n",
    "    # Date columns\n",
    "    for i in date_cols:\n",
    "        final_data[final_data[i].isnull() == False][i].apply(lambda x : str(x.year) +\n",
    "                                                \"-\" + str(x.month)).value_counts(ascending = True).plot()\n",
    "        plt.title(i + \" (\" + str(final_data[i].isnull().sum()) + \" null values)\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize continuous features\n",
    "...\n",
    "\n",
    "# visulaize categorical features\n",
    "...\n",
    "\n",
    "# visualize date columns\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are quite a few outliers. \n",
    "# Please identify top-k (decide this based on the visualization) features where outliers are most obvious\n",
    "n_rows = len(final_data)\n",
    "\n",
    "final_data = ... # remove outliers based 1st obvious feature\n",
    "final_data = ... # remove outliers based 2nd obvious feature\n",
    "...\n",
    "final_data = ... # remove outliers based kth obvious feature\n",
    "\n",
    "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove all loans that are still current\n",
    "n_rows = len(final_data)\n",
    "\n",
    "final_data = ...\n",
    "\n",
    "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only include loans isssued since 2010\n",
    "n_rows = len(final_data)\n",
    "\n",
    "final_data = ...\n",
    "\n",
    "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Deal with null values. We allow cateogrical variables to be null\n",
    "# OTHER than grade, which is a particularly important categorical.\n",
    "# All non-categorical variables must be non-null, and we drop\n",
    "# rows that do not meet this requirement\n",
    "\n",
    "required_cols = set(cols_to_pick) - set(cat_cols) - set([\"id\"])\n",
    "required_cols.add(\"grade\")\n",
    "\n",
    "n_rows = len(final_data)\n",
    "\n",
    "... # drop rows that contain null based only on \"required_cols\"\n",
    "\n",
    "print(\"Removed \" + str(n_rows - len(final_data)) + \" rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize the data again after cleaning\n",
    "...\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize the feature correlations\n",
    "... # use sns scatter or pairplot\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize relation between loan status and features\n",
    "... # sns pairplot or scatter plot. Refer to recitations\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you observe after removing the outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "Solution to Q.7 from the handout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the percentage of loans by grade, the default by grade,\n",
    "# and the return of each grade\n",
    "perc_by_grade = (final_data.grade.value_counts()*100/len(final_data)).sort_index()\n",
    "\n",
    "default_by_grade = final_data.groupby(\"grade\").apply(lambda x : (x.loan_status != \"Fully Paid\").sum()*100/len(x) )\n",
    "ret_by_grade_OPT = ... # average return for M2-Optimistic for each loan grade\n",
    "ret_by_grade_PESS = ... # average return for M1-Pessimistic for each loan grade\n",
    "ret_by_grade_INTa = ... # average return for M3\n",
    "ret_by_grade_INTb = ... # average return for M3\n",
    "int_rate_by_grade = ... # average interest rate for each grade\n",
    "\n",
    "combined = pd.DataFrame(perc_by_grade)\n",
    "combined.columns = ['perc_of_loans']\n",
    "combined['perc_default'] = default_by_grade\n",
    "combined['avg_int_rate'] = int_rate_by_grade\n",
    "combined['return_OPT'] = ret_by_grade_OPT\n",
    "combined['return_PESS'] = ret_by_grade_PESS\n",
    "combined['return_INTa'] = ret_by_grade_INTa\n",
    "combined['return_INTb'] = ret_by_grade_INTb\n",
    "combined['return_INTc'] = ret_by_grade_INTc\n",
    "\n",
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the output of previous cell, write down your answers to Q.7 from the handout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save a Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove the \"total_pymnt\" and \"recoveries\" from the list of continuous features\n",
    "continuous_features = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why did we remove `total_pymt` and `recoveries` from the data for the task of predicting whether to give loan or not, although these are highly predictive features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the prepared data for modeling in next Phase.\n",
    "pickle.dump( [final_data, discrete_features, continuous_features, ret_cols], open(pickle_file, \"wb\") )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
